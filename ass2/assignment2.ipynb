{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# COMP3411/9418 21T0 Assignment 2\n",
    "\n",
    "- Lecturer: Anna Trofimova\n",
    "- School of Computer Science and Engineering, UNSW Sydney\n",
    "- Last Update 26th January at 07:00am, 2021\n",
    "$$\n",
    "% macros\n",
    "\\newcommand{\\indep}{\\perp \\!\\!\\!\\perp}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student:\n",
    "Jie Mei, z5173405"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "This interactive notebook contains the instructions to complete assignment 2; You should submit this notebook with the code and answers in one single file in .ipybn format with the name assignment2.ipybn. **Write your name and zID in the cell above** (to edit the markdown text double-click the cell).\n",
    "\n",
    "There is a maximum file size cap of 5MB, so make sure your submission does not exceed this size. The submitted notebook should contain all your source code and answers. You can add new cells and use markdown text to organise and explain your implementation/answer.\n",
    "\n",
    "Submit your files using give. On a CSE Linux machine, type the following on the command-line:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ give cs3411 ass2 assignment2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission deadline is **3rd February at 11.59pm, 2021.** This is a hard deadline, no extentions will be granted (it is not our decision, it is the reality of the summer term courses)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Late Submission Policy \n",
    "The penalty is set at 20% per late day. This is a ceiling penalty, so if your submission is marked 12/20 and it was submitted two days late, you still get 12/20. If you submit 5 days later, then the penalty is 100% and your mark will be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plagiarism\n",
    "This is an individual assignment. Remember that **all** work submitted for this assignment must be your own **individual** work and no code\n",
    "sharing or copying is allowed. You may use code from the Internet only with suitable attribution\n",
    "of the source in your program. **Do not use public code repositories as your code might be copied.** Keep in mind that sharing parts of assignment solutions is a form of plagiarism. All submitted assignments will be run through plagiarism detection software to detect similarities to other submissions. You should carefully read the UNSW policy on academic integrity and plagiarism. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "\n",
    "Imagine that you have been hired as a Data Scientist by Amazon, and your first task is to evaluate customer sentiment towards their products. Many online stores selling Amazon products provide their customers with an option to leave a review, but they might not have a rating system, or the customers might choose to leave a review without rating. However, you still want to use these reviews in your report. Thus, you need to develop a reliable model that can automatically assign setiment given a review.\n",
    "\n",
    "To develop your model, you have been given a collection of customer reviews on products like Alexa Echo, Echo dots, Alexa Firesticks etc. with their corresponding ratings. The ratings vary from 1 to 5, but to simplify the problem, you will consider reviews with ratings 1 & 2 to have negative sentiment, with 3 having neutral sentiment,  and 4 & 5 having positive sentiment.\n",
    "* Negative: 1 & 2\n",
    "* Neutral: 3\n",
    "* Positive: 4 & 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "When working with a Jupyter notebook, you can edit the \\*.py files either in the Jupyter interface (in your browser) or with your favorite editor (e.g., PyCharm). Whenever you save a \\*.py file, the notebook will reload their content directly.\n",
    "\n",
    "**Do not create new markdown cells, if you want to comment on something then use Raw NBConvert cells.**\n",
    "\n",
    "Below are the libraries that you can use (and need) in this assignment. If you want to use a library that is not in the list then send us an email to confirm (use course email). \n",
    "\n",
    "Run the code below to import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Source\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import re\n",
    "import copy\n",
    "\n",
    "\n",
    "#  If you experience problems with downloading stopwords, uncomment and run the code below.\n",
    "#  It will launch NLTK Downloader application so you can download stopwords corpora manually.\n",
    "\n",
    "# import nltk\n",
    "# import ssl\n",
    "\n",
    "# try:\n",
    "#     _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# else:\n",
    "#     ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Data [2 marks]\n",
    "\n",
    "In this part of the assignment you need to import the Amazon reviews dataset and analyse its main properties.\n",
    "\n",
    "#### Task 1.1\n",
    "Import the dataset from *amazon_alexa.tsv* file, save it into the variable *data* and change the rating labels as follow: \n",
    " {1: 'negative', 2: 'negative', 3: 'neutral', 4: 'positive', 5: 'positive'}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Walnut Finish</td>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating       date         variation  \\\n",
       "0  positive  31-Jul-18  Charcoal Fabric    \n",
       "1  positive  31-Jul-18  Charcoal Fabric    \n",
       "2  positive  31-Jul-18    Walnut Finish    \n",
       "3  positive  31-Jul-18  Charcoal Fabric    \n",
       "4  positive  31-Jul-18  Charcoal Fabric    \n",
       "\n",
       "                                    verified_reviews  feedback  \n",
       "0                                      Love my Echo!         1  \n",
       "1                                          Loved it!         1  \n",
       "2  Sometimes while playing a game, you can answer...         1  \n",
       "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
       "4                                              Music         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code\n",
    "data = pd.read_csv('amazon_alexa.tsv', sep='\\t')\n",
    "data['rating'] = data['rating'].map({1: 'negative', 2: 'negative', 3: 'neutral', 4: 'positive', 5: 'positive'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to plot the data distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['rating'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give a simple description of the class frequency distribution across the full dataset. What do you notice about the distribution? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It can be clearly seen from the figure that the number of positive is far greater than negative and neutral, the number of positive is greater than 2500 and both negative and neutral are less than 500, and the number of negative is slightly greater than neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.2\n",
    "\n",
    "To reduce computation time in this task, your will use only the 1000 most frequent tokens from the vocabulary as attributes. Run the code below to convert the input text samples into a document-term matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      !  !!  &  &#34;Alexa,  &#34;Things  (which  ,  -  --  .  ...  worth  \\\n",
      "0     0   0  0            0            0       0  0  0   0  0  ...      0   \n",
      "1     0   0  0            0            0       0  0  0   0  0  ...      0   \n",
      "2     0   0  0            0            0       0  0  0   0  0  ...      0   \n",
      "3     0   0  0            0            0       0  0  0   0  0  ...      0   \n",
      "4     0   0  0            0            0       0  0  0   0  0  ...      0   \n",
      "...  ..  .. ..          ...          ...     ... .. ..  .. ..  ...    ...   \n",
      "3145  0   0  0            0            0       0  0  0   0  0  ...      0   \n",
      "3146  0   0  0            0            0       0  0  0   0  0  ...      0   \n",
      "3147  0   0  0            0            0       0  0  0   0  0  ...      1   \n",
      "3148  0   0  0            0            0       0  0  0   0  0  ...      0   \n",
      "3149  0   0  0            0            0       0  0  0   0  0  ...      0   \n",
      "\n",
      "      would  wouldn't  year  years  yet  yet.  you  you're  your  \n",
      "0         0         0     0      0    0     0    0       0     0  \n",
      "1         0         0     0      0    0     0    0       0     0  \n",
      "2         0         0     0      0    0     0    2       0     0  \n",
      "3         0         0     0      0    0     0    0       0     0  \n",
      "4         0         0     0      0    0     0    0       0     0  \n",
      "...     ...       ...   ...    ...  ...   ...  ...     ...   ...  \n",
      "3145      0         0     0      0    0     0    0       0     0  \n",
      "3146      0         0     0      0    0     0    0       0     0  \n",
      "3147      0         0     0      0    0     0    3       0     1  \n",
      "3148      0         0     0      0    0     0    1       1     0  \n",
      "3149      0         0     0      0    0     0    0       0     0  \n",
      "\n",
      "[3150 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer=lambda x: x.split(), max_features=1000)\n",
    "\n",
    "x_dense = vectorizer.fit_transform(data['verified_reviews'])\n",
    "x_sparse = pd.DataFrame.sparse.from_spmatrix(x_dense, columns=vectorizer.get_feature_names())\n",
    "print(x_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was written in the helper notebook that the original input representation is bad. Explain why a document-term matrix is a more suitable representation for machine learning tasks with text data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your answer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two variables *x_dense* and *x_sparce* both represent input data in a document-term form. Explain which one is preferable and why."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Decision Tree [2 marks]\n",
    "\n",
    "In this part you need to evaluate how classifier hyperparameters affect their performance. Consider a Decision Tree classifier that splits attributes based on the lowest entropy. For performance evaluation, assume that only the top 1000 most frequent tokens are used as attributes. The first 60% of samples should constitute the traing set while the remaining 40% of samples should constitute the test set.\n",
    "\n",
    "#### Task 2.1\n",
    "In the cell below place your code that computes performance measures for decision trees with different depth limits. <br> \n",
    "Consider the following cases: max_depth = 5, 10, 100, 200, None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.39      0.12      0.19        97\n",
      "     neutral       0.25      0.02      0.03        63\n",
      "    positive       0.88      0.98      0.93      1100\n",
      "\n",
      "    accuracy                           0.87      1260\n",
      "   macro avg       0.51      0.37      0.38      1260\n",
      "weighted avg       0.81      0.87      0.83      1260\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.21      0.27        97\n",
      "     neutral       0.23      0.05      0.08        63\n",
      "    positive       0.89      0.97      0.93      1100\n",
      "\n",
      "    accuracy                           0.87      1260\n",
      "   macro avg       0.50      0.41      0.43      1260\n",
      "weighted avg       0.82      0.87      0.84      1260\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.44      0.44        97\n",
      "     neutral       0.33      0.29      0.31        63\n",
      "    positive       0.93      0.93      0.93      1100\n",
      "\n",
      "    accuracy                           0.86      1260\n",
      "   macro avg       0.56      0.55      0.56      1260\n",
      "weighted avg       0.86      0.86      0.86      1260\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.47      0.45        97\n",
      "     neutral       0.34      0.32      0.33        63\n",
      "    positive       0.93      0.93      0.93      1100\n",
      "\n",
      "    accuracy                           0.86      1260\n",
      "   macro avg       0.57      0.57      0.57      1260\n",
      "weighted avg       0.86      0.86      0.86      1260\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.46      0.45        97\n",
      "     neutral       0.39      0.33      0.36        63\n",
      "    positive       0.93      0.93      0.93      1100\n",
      "\n",
      "    accuracy                           0.87      1260\n",
      "   macro avg       0.59      0.58      0.58      1260\n",
      "weighted avg       0.87      0.87      0.87      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code  \n",
    "y = data['rating']\n",
    "maxDepth = [5,10,100,200,None]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_sparse,y,test_size = 0.4)\n",
    "\n",
    "for depth in maxDepth:\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth = depth)\n",
    "    model = classifier.fit(x_train, y_train)\n",
    "    y_test_predicted = model.predict(x_test)\n",
    "    report = classification_report(y_test, y_test_predicted)\n",
    "    print(report)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.2\n",
    "In the cell below explain any difference in performance, and comment on metrics in relation to the depth limit."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Pre-processing [3 marks]\n",
    "\n",
    "In this part, you need to evaluate the effect that the pre-processing of input features has on the performance of three classifiers - Decision Tree (DT), Multinomial Naive Bayes (MNB), and  Artificial Neural Networks (ANN). For a Decision Tree classifier, use the parameters from Part2 but do not limit the depth. For a Artificial Neural Network classifier, set the number of hidden neurons to 200.\n",
    "\n",
    "For the performance evaluation, assume that the first 60% of samples constitutes the traing set while the remaining 40% of samples constitutes the test set. All tokens in the vocabulary should be used as attributes.\n",
    "Consider the following scenarios:\n",
    "1. No data pre-processing\n",
    "2. Removal of URLs and tokens that are not made of strings of letters, numbers, or symbols {â€™, #, @, $} delimited by spaces.\n",
    "3. Apply (2) and make all tokens lowercase.\n",
    "4. Apply (2), (3) and remove all stop words.\n",
    "\n",
    "#### Task 3.1\n",
    "In the cell below place your code that reflects the four scenarios of feature pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# case 1\n",
    "def preprocessing_1(x):\n",
    "    data_copy = x.copy()\n",
    "    return data_copy\n",
    "\n",
    "# case 2\n",
    "def preprocessing_2(x):\n",
    "    data_copy = preprocessing_1(x)\n",
    "    data_copy = data_copy.map(lambda x: re.sub(r'[^A-Za-z\\d\\'\\#\\@\\$\\s*]','',x))\n",
    "    data_copy = data_copy.map(lambda x: re.sub(r'https?\\S+','',x))\n",
    "    return data_copy\n",
    "\n",
    "# case 3\n",
    "def preprocessing_3(x):\n",
    "    data_copy = preprocessing_2(x)\n",
    "    data_copy = data_copy.str.lower()\n",
    "    return data_copy\n",
    "\n",
    "# case 4\n",
    "def preprocessing_4(x):\n",
    "    data_copy = preprocessing_3(x)\n",
    "    stop = stopwords.words('english')\n",
    "    data_copy = data_copy.str.split().map(lambda x: [words for words in x if words not in stop])\n",
    "    data_copy = data_copy.map(lambda x: ' '.join([str(elem) for elem in x]) )\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3.2 \n",
    "\n",
    "In the cell below, place your code that trains and tests all three classifiers. Pre-process your data according on scenario #4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test Decision Tree=========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.42      0.39       108\n",
      "     neutral       0.22      0.18      0.20        67\n",
      "    positive       0.91      0.91      0.91      1085\n",
      "\n",
      "    accuracy                           0.83      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.83      0.83      0.83      1260\n",
      "\n",
      "=========Test Multinomial Naive Bayes=========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.32      0.43       108\n",
      "     neutral       0.20      0.18      0.19        67\n",
      "    positive       0.91      0.96      0.93      1085\n",
      "\n",
      "    accuracy                           0.86      1260\n",
      "   macro avg       0.58      0.49      0.52      1260\n",
      "weighted avg       0.84      0.86      0.85      1260\n",
      "\n",
      "=========Test Artificial Neural Networks=========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.27      0.32       108\n",
      "     neutral       0.28      0.13      0.18        67\n",
      "    positive       0.90      0.96      0.93      1085\n",
      "\n",
      "    accuracy                           0.86      1260\n",
      "   macro avg       0.53      0.45      0.48      1260\n",
      "weighted avg       0.82      0.86      0.84      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code   \n",
    "pre_4 = preprocessing_4(data['verified_reviews'])\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x.split(), max_features=1000)\n",
    "x_dense = vectorizer.fit_transform(pre_4)\n",
    "x_sparse = pd.DataFrame.sparse.from_spmatrix(x_dense, columns=vectorizer.get_feature_names())\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_sparse,y,test_size = 0.4,shuffle = False)\n",
    "\n",
    "\n",
    "print(\"=========Test Decision Tree=========\")\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "model = classifier.fit(x_train, y_train)\n",
    "y_test_predicted = model.predict(x_test)\n",
    "report = classification_report(y_test, y_test_predicted)\n",
    "print(report)\n",
    "print(\"=========Test Multinomial Naive Bayes=========\")\n",
    "classifier = MultinomialNB()\n",
    "model = classifier.fit(x_train, y_train)\n",
    "y_test_predicted = model.predict(x_test)\n",
    "report = classification_report(y_test, y_test_predicted)\n",
    "print(report)\n",
    "print(\"=========Test Artificial Neural Networks=========\")\n",
    "classifier = MLPClassifier(hidden_layer_sizes = 200)\n",
    "model = classifier.fit(x_train, y_train)\n",
    "y_test_predicted = model.predict(x_test)\n",
    "report = classification_report(y_test, y_test_predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3.3\n",
    "\n",
    "Evaluate the effect each pre-processing scenario has on the performance for the three models. In each case. compute the performance metrics. Write your answer in the cell below. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 [5 marks]\n",
    "\n",
    "In this part, you need to evaluate how the number of features and classes affects the performance of the three classifiers - Decision Tree (DT), Multinomial Naive Bayes (MNB), and Artificial Neural Networks (ANN). For a Decision Tree classifier, use the parameters from Part 2 but do not limit the depth. For a Artificial Neural Network classifier set the number of hidden neurons to 200.\n",
    "\n",
    "For the performance evaluation, assume that the first 60% of samples constitute the traing set while the remaining 40% of samples constitute the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.1\n",
    "\n",
    "Consider the following scenarios for attributes:\n",
    "\n",
    "1. Attributes are all tokens in the vocabulary\n",
    "2. Attributes are the top 1000 most frequent tokens in the vocabulary\n",
    "3. Attributes are the top 100 most frequent tokens in the vocabulary\n",
    "4. Attributes are the top 10 most frequent tokens in the vocabulary\n",
    "\n",
    "In the cell below, place your code that returns a document-term representation given the number of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "\n",
    "def limit_attributes(x, n_attributes):\n",
    "    vectorizer = CountVectorizer(analyzer=lambda x: x.split(), max_features=n_attributes)\n",
    "    x_dense = vectorizer.fit_transform(x)\n",
    "    x_sparse = pd.DataFrame.sparse.from_spmatrix(x_dense, columns=vectorizer.get_feature_names())\n",
    "    return x_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.2 \n",
    "\n",
    "In the cell below, place your code that trains and tests all three classifiers. Limit the number of attributes according on scenario #4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test Decision Tree=========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.28      0.10      0.14       103\n",
      "     neutral       0.35      0.13      0.19        60\n",
      "    positive       0.88      0.97      0.92      1097\n",
      "\n",
      "    accuracy                           0.86      1260\n",
      "   macro avg       0.50      0.40      0.42      1260\n",
      "weighted avg       0.81      0.86      0.83      1260\n",
      "\n",
      "=========Test Multinomial Naive Bayes=========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.15      0.04      0.06       103\n",
      "     neutral       0.50      0.02      0.03        60\n",
      "    positive       0.87      0.98      0.92      1097\n",
      "\n",
      "    accuracy                           0.86      1260\n",
      "   macro avg       0.51      0.35      0.34      1260\n",
      "weighted avg       0.80      0.86      0.81      1260\n",
      "\n",
      "=========Test Artificial Neural Networks=========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.06      0.10       103\n",
      "     neutral       0.50      0.02      0.03        60\n",
      "    positive       0.87      0.99      0.93      1097\n",
      "\n",
      "    accuracy                           0.87      1260\n",
      "   macro avg       0.57      0.35      0.35      1260\n",
      "weighted avg       0.81      0.87      0.82      1260\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiem/opt/anaconda3/envs/Comp3411/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "x = preprocessing_4(data['verified_reviews'])\n",
    "x_sparse = limit_attributes(x,10)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_sparse,y,test_size = 0.4)\n",
    "\n",
    "\n",
    "print(\"=========Test Decision Tree=========\")\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "model = classifier.fit(x_train, y_train)\n",
    "y_test_predicted = model.predict(x_test)\n",
    "report = classification_report(y_test, y_test_predicted)\n",
    "print(report)\n",
    "print(\"=========Test Multinomial Naive Bayes=========\")\n",
    "classifier = MultinomialNB()\n",
    "model = classifier.fit(x_train, y_train)\n",
    "y_test_predicted = model.predict(x_test)\n",
    "report = classification_report(y_test, y_test_predicted)\n",
    "print(report)\n",
    "print(\"=========Test Artificial Neural Networks=========\")\n",
    "classifier = MLPClassifier(hidden_layer_sizes = 200)\n",
    "model = classifier.fit(x_train, y_train)\n",
    "y_test_predicted = model.predict(x_test)\n",
    "report = classification_report(y_test, y_test_predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.3\n",
    "\n",
    "Evaluate the effect each scenario has on the performance for the three models based on the performance metrics. Explain the differences in the performance. Write your answer in the cell below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.4\n",
    "\n",
    "Remove all samples with neutral sentiment from the dataset. Train and test all three models on this new dataset, computing the preformance measures as well. Assume that the first 60% of samples constitute the traing set while the remaining 40% of samples constitute the test set. All tokens in the vocabulary should be used as attributes.\n",
    "\n",
    "Place your code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test Decision Tree=========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.53      0.49        89\n",
      "    positive       0.96      0.95      0.96      1111\n",
      "\n",
      "    accuracy                           0.92      1200\n",
      "   macro avg       0.71      0.74      0.72      1200\n",
      "weighted avg       0.92      0.92      0.92      1200\n",
      "\n",
      "=========Test Multinomial Naive Bayes=========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.46      0.54        89\n",
      "    positive       0.96      0.98      0.97      1111\n",
      "\n",
      "    accuracy                           0.94      1200\n",
      "   macro avg       0.80      0.72      0.75      1200\n",
      "weighted avg       0.93      0.94      0.94      1200\n",
      "\n",
      "=========Test Artificial Neural Networks=========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.37      0.47        89\n",
      "    positive       0.95      0.98      0.97      1111\n",
      "\n",
      "    accuracy                           0.94      1200\n",
      "   macro avg       0.79      0.68      0.72      1200\n",
      "weighted avg       0.93      0.94      0.93      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "data_copy = data.copy()\n",
    "data_copy = data_copy.drop(data_copy[data_copy['rating'] == 'neutral'].index)\n",
    "data_copy = data_copy.reset_index(drop=True)\n",
    "pre_4 = preprocessing_4(data_copy['verified_reviews'])\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x.split(), max_features=1000)\n",
    "x_dense = vectorizer.fit_transform(pre_4)\n",
    "x_sparse = pd.DataFrame.sparse.from_spmatrix(x_dense, columns=vectorizer.get_feature_names())\n",
    "y = data_copy['rating']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_sparse,y,test_size = 0.4)\n",
    "\n",
    "\n",
    "print(\"=========Test Decision Tree=========\")\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "model = classifier.fit(x_train, y_train)\n",
    "y_test_predicted = model.predict(x_test)\n",
    "report = classification_report(y_test, y_test_predicted)\n",
    "print(report)\n",
    "print(\"=========Test Multinomial Naive Bayes=========\")\n",
    "classifier = MultinomialNB()\n",
    "model = classifier.fit(x_train, y_train)\n",
    "y_test_predicted = model.predict(x_test)\n",
    "report = classification_report(y_test, y_test_predicted)\n",
    "print(report)\n",
    "print(\"=========Test Artificial Neural Networks=========\")\n",
    "classifier = MLPClassifier(hidden_layer_sizes = 200)\n",
    "model = classifier.fit(x_train, y_train)\n",
    "y_test_predicted = model.predict(x_test)\n",
    "report = classification_report(y_test, y_test_predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.5\n",
    "Compare these results to the results obtained in scenario #1 (part 4). Is there any difference in the metrics for either of the classes (i.e. consider positive and negative classes individually)?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 [8 marks]\n",
    "\n",
    "In this part you need to develop your own method (pipeline) for sentiment analysis. You can create new code cells (to place your code) and Raw NBConvert cells (to descibe the steps you are taking to develop your model, or make a comment).\n",
    "\n",
    "You can use either Decision Tree, Multinomial Naive Bayes (MNB), or Artificial Neural Network (ANN) classifiers. If you use parameters for your classifier, the you need to justify the values that you chose for them in writing or in coding & writing (if it is based on evaluation resuts) - similar to Part 2.\n",
    "\n",
    "Since this part of the assignment carries the highest mark, the explanation of your method and its evaluation should be descibed in detail.\n",
    "\n",
    "Optionally: you can also make plots to visualize your findings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
